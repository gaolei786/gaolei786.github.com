---
layout: post
title: 交叉验证
author: <a href="http://gaolei786.github.com/">GaoLei</a>
categories:
- Statistics
show_img: "/images/nlm2.png"
---

对交叉验证这个问题，一直以来，不明白是怎么回事。近期看材料，涉及到了这个问题，写的通俗易懂，有种恍然大悟的感觉。下面，我写下对这个问题的理解。

现在假设这里有一堆数据，作为统计er的任务就是从这些数据中提取有用的信息。如何提取信息呢，我们的法宝就是--模型。模型在统计当中是极其重要的，学统计就是跟各种各样的模型混个脸熟。在模型的基础上，我们利用数据对模型的参数进行估计，从而通过参数化后的模型来描述数据的内在关系，了解数据内在的关系（pattern)非常必要，有助于对未来进行预测。

那么对于手里的数据，我们该套用什么样的模型呢？事实上，对于一个数据分析问题而言，可用的模型不只一个，不存在所谓最优的模型。你不能说，某个模型是最好的，其他模型都是不可取的，某个模型在某个问题下，可能解释能力优于其他模型，但这并不意味着在该类问题下，该模型就是万能的，可能换一种评价标准，这种模型就不是最好的。我们的任务是从几个备选模型中，按照某种评价标准，选择出较为合理的一个模型。

一个直接的想法是比较各个模型的对数据的拟合效果。例如，对于一个$x,y$数据而言，线性回归的残差平方和可能比非线性回归的残差平方和要小，这时我们说，线性回归拟合效果更好，线性回归模型是理想的选择。但是这种比较方式存在一种缺陷---过拟合问题。有些模型，对原始数据拟合相当好，但是它的预测效果却出奇的差。更重要的是，数据分析的最终目的并不是拟合数据，而是对未来进行预测。一个合理的模型一方面可以拟合原始数据，另一方面又应该可以以高准确率进行预测。所以进行模型选择时，要综合考虑这两方面因素。情况常常是，拟合效果和预测误差二者鱼和熊掌不能兼得，我们需要在二者之间寻找一种平衡。

交叉验证就是基于这样的考虑。我们以K折交叉验证（k-folded cross validation)来说明它的具体步骤。$$ \{A_{1},A_{2}, A_{3}, A_{4}, A_{5}, A_{6}, A_{7}, A_{8}, A_{9}\} $$

为了简化，取k=10。在原始数据A的基础上，我们随机抽取一组观测，构成一个数据子集（容量固定）,记为$$  A_{1}  $$ 重复以上过程10次，我们就会获得一个数据子集集合    　　　　      $$ \{A_{1}, A_{2}, A_{3}, A_{4}, A_{5}, A_{6}, A_{7}, A_{8}, A_{9}, A_{10}\} $$。

接下来，我们首先对模型$$M_{1}$$进行交叉验证，如下,

- 在$$\{A_{2}, A_{3}, A_{4}, A_{5}, A_{6}, A_{7}, A_{8}, A_{9}, A_{10}\}$$基础上构建模型$$M_{1}$$，并对数据集$$A_{1}$$进行验证，将预测值与真值进行比较，在某一评价标准下，计算一个得分$$a_{1,1}$$.
- 在$$\{A_{1}, A_{3}, A_{4}, A_{5}, A_{6}, A_{7}, A_{8}, A_{9}, A_{10}\}$$基础上构建模型$$M_{1}$$，并对数据集$$A_{2}$$进行验证，将预测值与真值进行比较，在同一评价标准下，计算一个得分$$a_{1,2}$$.
- ......
- 在$$\{A_{1},A_{2}, A_{3}, A_{4}, A_{5}, A_{6}, A_{7}, A_{8}, A_{9}\}$$基础上构建模型，并对数据集$$A_{10}$$进行验证，将预测值与真值进行比较，在同一评价标准下，计算一个得分$$a_{1,10}$$.
- $$a_1=\frac{a_{1,1}+a_{1,2}+\ldots+a_{1,10}}{10}$$作为模型$$M_{1}$$的综合得分。

对每个模型都这样过一遍，最后得到了每个模型的一个得分，按照得分，我们就可以选择最合理的模型。

将数据打成好多份，交叉验证模型，很有点bootstrap的意思，bootstrap的思想渗透到了统计学的各个领域了已经。


除了K折交叉验证，另外两种交叉验证为Hold Out 验证和留一验证：

Hold验证：常识来说，Holdout 验证并非一种交叉验证，因为数据并没有交叉使用。 随机从最初的样本中选出部分，形成交叉验证数据，而剩余的就当做训练数据。 一般来说，少于原本样本三分之一的数据被选做验证数据。

留一验证：
正如名称所建议， 留一验证（LOOCV）意指只使用原本样本中的一项来当做验证资料， 而剩余的则留下来当做训练资料。 这个步骤一直持续到每个样本都被当做一次验证资料。 事实上，这等同于 K-fold 交叉验证是一样的，其中K为原本样本个数。 


---
参考：

- [交叉验证(维基百科)](http://zh.wikipedia.org/wiki/%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89)
- [交叉验证（百度百科）](http://baike.baidu.com/view/1211084.htm)
- Data Mining with R：Learning with Case Studies



---







